{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:25:44.478096: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute main path\n",
    "main_path = '../data/'\n",
    "\n",
    "# Read JSON file into a DataFrame with unprocessed instance col\n",
    "wlas_df = pd.read_json(main_path + 'WLASL_v0.3.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids of the current instance\n",
    "\n",
    "    Input: instance json list\n",
    "    Output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_list = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_list.append(video_id)\n",
    "    return videos_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_features(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids and url or any other featrue of the current instance\n",
    "\n",
    "    input: instance json list\n",
    "    output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_ids = []\n",
    "    videos_urls = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        video_url = ins['url']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_ids.append(video_id)\n",
    "            videos_urls.append(video_url)\n",
    "    return videos_ids, videos_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open JSON file (read only)\n",
    "with open(main_path+'WLASL_v0.3.json', 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "instance_json = json.loads(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "      <th>videos_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "      <td>[69241, 07069, 07068, 07070, 07099, 07074]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[69302, 65539, 17710, 17733, 65540, 17734, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[12328, 12312, 12311, 12338, 12313, 12314, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[05728, 05749, 05750, 05729, 05730, 65167, 057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[09848, 09869, 09849, 09850, 09851, 65328, 09854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>washington</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62393, 62394, 62395, 62396, 62398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>waterfall</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62488, 62489, 62490, 62492, 62493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>weigh</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62782, 62783, 62785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>[{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[63044, 63046, 63047, 63050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>whistle</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[63186, 63188, 63190]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gloss                                          instances  \\\n",
       "0           book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...   \n",
       "1          drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...   \n",
       "2       computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "3         before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "4          chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "...          ...                                                ...   \n",
       "1995  washington  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1996   waterfall  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1997       weigh  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1998  wheelchair  [{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...   \n",
       "1999     whistle  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "\n",
       "                                             videos_ids  \n",
       "0            [69241, 07069, 07068, 07070, 07099, 07074]  \n",
       "1     [69302, 65539, 17710, 17733, 65540, 17734, 177...  \n",
       "2     [12328, 12312, 12311, 12338, 12313, 12314, 123...  \n",
       "3     [05728, 05749, 05750, 05729, 05730, 65167, 057...  \n",
       "4     [09848, 09869, 09849, 09850, 09851, 65328, 09854]  \n",
       "...                                                 ...  \n",
       "1995                [62393, 62394, 62395, 62396, 62398]  \n",
       "1996                [62488, 62489, 62490, 62492, 62493]  \n",
       "1997                              [62782, 62783, 62785]  \n",
       "1998                       [63044, 63046, 63047, 63050]  \n",
       "1999                              [63186, 63188, 63190]  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get available video ids for all rows in wlas_df and add to new col 'videos_id'\n",
    "wlas_df['videos_ids'] = wlas_df['instances'].apply(get_videos_ids)\n",
    "wlas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>69241</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>07069</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>07068</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>07070</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>07099</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63047</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/5/5233.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63050</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/wheelcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63186</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63188</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/9/9961.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63190</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/whistle.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word video_id                                                url\n",
       "index                                                                        \n",
       "0            book    69241       http://aslbricks.org/New/ASL-Videos/book.mp4\n",
       "1            book    07069  https://signstock.blob.core.windows.net/signsc...\n",
       "2            book    07068  https://s3-us-west-1.amazonaws.com/files.start...\n",
       "3            book    07070  https://media.asldeafined.com/vocabulary/14666...\n",
       "4            book    07099     http://www.aslsearch.com/signs/videos/book.mp4\n",
       "...           ...      ...                                                ...\n",
       "11975  wheelchair    63047  https://www.signingsavvy.com/signs/mp4/5/5233.mp4\n",
       "11976  wheelchair    63050  http://www.aslsearch.com/signs/videos/wheelcha...\n",
       "11977     whistle    63186  https://media.spreadthesign.com/video/mp4/13/9...\n",
       "11978     whistle    63188  https://www.signingsavvy.com/signs/mp4/9/9961.mp4\n",
       "11979     whistle    63190  http://www.aslsearch.com/signs/videos/whistle.mp4\n",
       "\n",
       "[11980 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate DataFrame for available information in each instance\n",
    "features_df = pd.DataFrame(columns=['word', 'video_id', 'url'])\n",
    "\n",
    "for row in wlas_df.iterrows():\n",
    "    # Extract ids and urls for each row\n",
    "    ids, urls = get_json_features(row[1][1])\n",
    "    # Initialize a list matching the length (n) of found ids containing the word\n",
    "    word = [row[1][0]] * len(ids)\n",
    "    # Using zip to create new df with:\n",
    "    # n * word in gloss col (e.g. 6 * book)\n",
    "    # Unique id and url in ids and url col respectively\n",
    "    df = pd.DataFrame(list(zip(word, ids, urls)), columns = features_df.columns)\n",
    "    # Append temporary df to feature_df\n",
    "    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "# Renaming index col to index\n",
    "features_df.index.name = 'index'\n",
    "features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Define 20 target classes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 20 words were selected based on the amount of samples available\n",
    "\n",
    "selected_words = [\n",
    "    'like', 'work', 'play', 'take', 'call',\n",
    "    'go', 'study', 'give', 'write', 'yesterday',\n",
    "    'far', 'hot', 'cold', 'good', 'bad',\n",
    "    'computer', 'apple', 'doctor', 'family', 'dog'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = features_df[features_df['word'].isin(selected_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_id in selected_df['video_id']:\n",
    "    if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "        cap = cv2.VideoCapture(f'{main_path}videos/{video_id}.mp4')\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        selected_df.loc[selected_df['video_id'] == video_id, ['video_length']] = int(length)\n",
    "    pass\n",
    "\n",
    "selected_df = selected_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Defining the Input/Features: X #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame sampling parameters\n",
    "frames_per_video = 10\n",
    "target_size = (150, 150)\n",
    "# Initialize empty array of desired shape\n",
    "X = np.empty((219, frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Function to perform frame sampling\n",
    "def sample_frames(video_path, frames_per_video, total_frames):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_indices = []\n",
    "\n",
    "    while len(set(frame_indices)) != frames_per_video:\n",
    "        frame_indices = sorted(np.random.uniform(0, total_frames-5, frames_per_video).astype(int))\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_counter in frame_indices:\n",
    "                # Resize frame to required size\n",
    "                frame = cv2.resize(frame, target_size)\n",
    "                # CV2 output BGR -> converting to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Append to list of frames\n",
    "                frames.append(frame_rgb)\n",
    "\n",
    "            frame_counter += 1\n",
    "\n",
    "            if len(frames) == frames_per_video:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x7f97304ca200] Invalid NAL unit size (745 > 472).\n",
      "[h264 @ 0x7f97304ca200] Error splitting the input into NAL units.\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x7f9730dd5c40] stream 1, offset 0x3b468: partial file\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "for i, row in selected_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    total_frames = row['video_length']\n",
    "    video_path = f'../data/videos/{video_id}.mp4'\n",
    "\n",
    "    sampled_frames = sample_frames(video_path, frames_per_video, total_frames)\n",
    "\n",
    "    # Assign sampled frames to results array\n",
    "    X[i] = np.array(sampled_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X has been initialized with Shape (219, 10, 150, 150, 3)!\n"
     ]
    }
   ],
   "source": [
    "if X.shape == (219, 10, 150, 150, 3):\n",
    "    print(f'✅ X has been initialized with Shape {X.shape}!')\n",
    "else:\n",
    "    print('❌ X has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Defining the Output/Target: y #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "selected_df['encoded_word'] = label_encoder.fit_transform(selected_df['word'])\n",
    "y_cat = tf.keras.utils.to_categorical(selected_df['encoded_word'], num_classes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ y has been initialized with Shape (219, 20)!\n"
     ]
    }
   ],
   "source": [
    "if y_cat.shape == (219, 20):\n",
    "    print(f'✅ y has been initialized with Shape {y_cat.shape}!')\n",
    "else:\n",
    "    print('❌ y has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Testing 3D CNN Model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: remotezip in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (0.12.1)\n",
      "Requirement already satisfied: tqdm in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: opencv-python in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: einops in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (0.7.0)\n",
      "Requirement already satisfied: requests in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from remotezip) (2.31.0)\n",
      "Requirement already satisfied: tabulate in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from remotezip) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from requests->remotezip) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from requests->remotezip) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from requests->remotezip) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/roshnikumar/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages (from requests->remotezip) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install remotezip tqdm opencv-python einops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tqdm\n",
    "import random\n",
    "import pathlib\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers, models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the new simplified model with around 50k params:\n",
    "input_shape = (10, 150, 150, 3)\n",
    "num_classes = 20\n",
    "\n",
    "def create_3d_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    model.add(layers.Conv3D(32, kernel_size=(3,3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(1,2,2)))\n",
    "\n",
    "    model.add(layers.Conv3D(16, kernel_size=(3,3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(1,2,2)))\n",
    "\n",
    "    model.add(layers.Conv3D(8, kernel_size=(3,3,3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling3D(pool_size=(1,2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(3, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d (Conv3D)             (None, 8, 148, 148, 32)   2624      \n",
      "                                                                 \n",
      " max_pooling3d (MaxPooling3D  (None, 8, 74, 74, 32)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3d_1 (Conv3D)           (None, 6, 72, 72, 16)     13840     \n",
      "                                                                 \n",
      " max_pooling3d_1 (MaxPooling  (None, 6, 36, 36, 16)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " conv3d_2 (Conv3D)           (None, 4, 34, 34, 8)      3464      \n",
      "                                                                 \n",
      " max_pooling3d_2 (MaxPooling  (None, 4, 17, 17, 8)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9248)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 27747     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 3)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 20)                80        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47,755\n",
      "Trainable params: 47,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-22 16:26:12.007205: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_3d_cnn_model(input_shape=input_shape, num_classes=num_classes)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "def model_compile(model):\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "model = model_compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219, 10, 150, 150, 3)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = y_cat\n",
    "X_CNN = X/255.\n",
    "\n",
    "X_CNN_train, X_CNN_val, y_CNN_train, y_CNN_val = train_test_split(X_CNN, y, train_size=0.6, random_state=42)\n",
    "X_CNN.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define 3D CNN and compile\n",
    "# model = create_3d_cnn_model(num_classes=20, input_shape=input_shape)\n",
    "# model = model_compile(model)\n",
    "\n",
    "# # Model.fit and plot\n",
    "# history = model.fit(\n",
    "#     X_CNN_train,\n",
    "#     y_CNN_train,\n",
    "#     epochs=100,\n",
    "#     batch_size=8,\n",
    "#     validation_data=(X_CNN_val, y_CNN_val),\n",
    "#     verbose=0\n",
    "# )\n",
    "# print(f\"✅ (Run {j+1}) RNN is now fit\")\n",
    "\n",
    "# plot_accuracy(history)\n",
    "# print(round(history.__dict__[\"history\"][\"val_accuracy\"][-1],3))\n",
    "# print(f\"✅ {results2['model'][j]} completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SignFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
