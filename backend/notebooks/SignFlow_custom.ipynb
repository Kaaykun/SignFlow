{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 16:23:29.018611: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 16:23:29.480248: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 16:23:29.492565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/eigot/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-11-27 16:23:29.492581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-27 16:23:29.521753: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 16:23:30.956555: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/eigot/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-11-27 16:23:30.956701: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/eigot/.pyenv/versions/3.10.6/envs/SignFlow/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-11-27 16:23:30.956707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 20 words were selected based on the amount of samples available\n",
    "# selected_words = [\n",
    "#     'like', 'work', 'play', 'take', 'call',\n",
    "#     'go', 'study', 'give', 'write', 'yesterday',\n",
    "#     'far', 'hot', 'cold', 'good', 'bad',\n",
    "#     'computer', 'apple', 'doctor', 'family', 'dog'\n",
    "# ]\n",
    "# selected_words = ['work','study', 'write', 'hot', 'cold', 'family']\n",
    "selected_words = ['hello',\n",
    "'bye',\n",
    "'world',\n",
    "'yes',\n",
    "'no',\n",
    "'I',\n",
    "'you',\n",
    "'go',\n",
    "'work',\n",
    "'drink',\n",
    "'beer',\n",
    "'many',\n",
    "'what',\n",
    "'thankyou',\n",
    "'love']\n",
    "\n",
    "# selected_words = ['hello',\n",
    "# 'world',\n",
    "# 'I',\n",
    "# 'drink',\n",
    "# 'beer',\n",
    "# 'many',\n",
    "# 'thankyou']\n",
    "\n",
    "# selected_words = ['hello',\n",
    "# 'bye',\n",
    "# 'world',\n",
    "# 'yes',\n",
    "# 'no',\n",
    "# 'I']\n",
    "\n",
    "n_classes = len(selected_words)\n",
    "\n",
    "# Absolute main path\n",
    "main_path = '../data/custom_videos/'\n",
    "\n",
    "# Frame sampling parameters\n",
    "frames_per_video = 20\n",
    "target_size = (480, 480)\n",
    "\n",
    "# Dataset multiplier\n",
    "number_of_augmentations = 0\n",
    "\n",
    "# Train split parameters\n",
    "train_size = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read JSON file into a DataFrame with unprocessed instance col\n",
    "# wlas_df = pd.read_json(main_path + 'WLASL_v0.3.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids of the current instance\n",
    "\n",
    "    Input: instance json list\n",
    "    Output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_list = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_list.append(video_id)\n",
    "    return videos_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_features(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids and url or any other featrue of the current instance\n",
    "\n",
    "    input: instance json list\n",
    "    output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_ids = []\n",
    "    videos_urls = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        video_url = ins['url']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_ids.append(video_id)\n",
    "            videos_urls.append(video_url)\n",
    "    return videos_ids, videos_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open JSON file (read only)\n",
    "# with open(main_path+'WLASL_v0.3.json', 'r') as data_file:\n",
    "#     json_data = data_file.read()\n",
    "\n",
    "# instance_json = json.loads(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get available video ids for all rows in wlas_df and add to new col 'videos_id'\n",
    "# wlas_df['videos_ids'] = wlas_df['instances'].apply(get_videos_ids)\n",
    "# wlas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye_Benjamin_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>love_Eigo_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many</td>\n",
       "      <td>many_Benjamin_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world</td>\n",
       "      <td>world_Jaris_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankyou</td>\n",
       "      <td>thankyou_Benjamin_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>world</td>\n",
       "      <td>world_Jaris_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye_Eigo_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>go</td>\n",
       "      <td>go_Roshni_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>drink</td>\n",
       "      <td>drink_Jaris_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>no</td>\n",
       "      <td>no_Eigo_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word             video_id\n",
       "0         bye       bye_Benjamin_4\n",
       "1        love          love_Eigo_4\n",
       "2        many      many_Benjamin_4\n",
       "3       world        world_Jaris_4\n",
       "4    thankyou  thankyou_Benjamin_2\n",
       "..        ...                  ...\n",
       "295     world        world_Jaris_3\n",
       "296       bye           bye_Eigo_2\n",
       "297        go          go_Roshni_3\n",
       "298     drink        drink_Jaris_2\n",
       "299        no            no_Eigo_3\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate DataFrame for available information in each instance\n",
    "features_df = pd.DataFrame(columns=['word', 'video_id'])\n",
    "\n",
    "for filename in os.listdir(\"../data/custom_videos/\"):\n",
    "    word = filename.split(\"_\")[0]\n",
    "    filename = filename.replace(\".mp4\",\"\")\n",
    "    df = pd.DataFrame([[word, filename]], columns=features_df.columns)\n",
    "    # Append temporary df to feature_df\n",
    "    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "# Renaming index col to index\n",
    "# features_df.index.name = 'index'\n",
    "features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Define 20 target classes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = features_df[features_df['word'].isin(selected_words)]\n",
    "selected_df[\"video_length\"]=60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye_Benjamin_4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love</td>\n",
       "      <td>love_Eigo_4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>many</td>\n",
       "      <td>many_Benjamin_4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>world</td>\n",
       "      <td>world_Jaris_4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thankyou</td>\n",
       "      <td>thankyou_Benjamin_2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>world</td>\n",
       "      <td>world_Jaris_3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>bye</td>\n",
       "      <td>bye_Eigo_2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>go</td>\n",
       "      <td>go_Roshni_3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>drink</td>\n",
       "      <td>drink_Jaris_2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>no</td>\n",
       "      <td>no_Eigo_3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word             video_id  video_length\n",
       "0         bye       bye_Benjamin_4            60\n",
       "1        love          love_Eigo_4            60\n",
       "2        many      many_Benjamin_4            60\n",
       "3       world        world_Jaris_4            60\n",
       "4    thankyou  thankyou_Benjamin_2            60\n",
       "..        ...                  ...           ...\n",
       "295     world        world_Jaris_3            60\n",
       "296       bye           bye_Eigo_2            60\n",
       "297        go          go_Roshni_3            60\n",
       "298     drink        drink_Jaris_2            60\n",
       "299        no            no_Eigo_3            60\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for video_id in selected_df['video_id']:\n",
    "    if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "        cap = cv2.VideoCapture(f'{main_path}videos/{video_id}.mp4')\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        selected_df.loc[selected_df['video_id'] == video_id, ['video_length']] = int(length)\n",
    "    pass\n",
    "\n",
    "selected_df = selected_df.reset_index(drop=True)\n",
    "input_length = len(selected_df)\n",
    "selected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Defining the Input/Features: X #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty array of desired shape\n",
    "X = np.empty((input_length, frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Function to perform frame sampling\n",
    "def sample_frames(video_path, frames_per_video, total_frames):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_indices = []\n",
    "\n",
    "    while len(set(frame_indices)) != frames_per_video:\n",
    "        frame_indices = sorted(np.random.uniform(0, total_frames-5, frames_per_video).astype(int))\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_counter in frame_indices:\n",
    "                # Resize frame to required size\n",
    "                frame = cv2.resize(frame, target_size)\n",
    "                # CV2 output BGR -> converting to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Append to list of frames\n",
    "                frames.append(frame_rgb)\n",
    "\n",
    "            frame_counter += 1\n",
    "\n",
    "            if len(frames) == frames_per_video:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "for i, row in selected_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    total_frames = row['video_length']\n",
    "    video_path = f'../data/custom_videos/{video_id}.mp4'\n",
    "\n",
    "    sampled_frames = sample_frames(video_path, frames_per_video, total_frames)\n",
    "\n",
    "    # Assign sampled frames to results array\n",
    "    X[i] = np.array(sampled_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X has been initialized with Shape (300, 20, 480, 480, 3)!\n"
     ]
    }
   ],
   "source": [
    "if X.shape == (len(selected_df), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X has been initialized with Shape {X.shape}!')\n",
    "else:\n",
    "    print('❌ X has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Defining the Output/Target: y #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "selected_df['encoded_word'] = label_encoder.fit_transform(selected_df['word'])\n",
    "y_cat = tf.keras.utils.to_categorical(selected_df['encoded_word'], num_classes=n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bye': 2,\n",
       " 'love': 6,\n",
       " 'many': 7,\n",
       " 'world': 12,\n",
       " 'thankyou': 9,\n",
       " 'work': 11,\n",
       " 'hello': 5,\n",
       " 'go': 4,\n",
       " 'yes': 13,\n",
       " 'you': 14,\n",
       " 'beer': 1,\n",
       " 'I': 0,\n",
       " 'drink': 3,\n",
       " 'what': 10,\n",
       " 'no': 8}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_df['encoded_word'] = label_encoder.fit_transform(selected_df['word'])\n",
    "label_to_number = dict(zip(selected_df['word'], selected_df['encoded_word']))\n",
    "label_to_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ y has been initialized with Shape (300, 15)!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if y_cat.shape == (input_length, n_classes):\n",
    "    print(f'✅ y has been initialized with Shape {y_cat.shape}!')\n",
    "else:\n",
    "    print('❌ y has not been initialized properly!')\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Restore sampled frames into .mp4 files and write CSV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_processed_videos(X):\n",
    "    \"\"\"\n",
    "    Generate processed videos from sampled frames.\n",
    "\n",
    "    Parameters:\n",
    "    - X (numpy.ndarray): Array containing sampled frames for multiple videos.\n",
    "    - output_folder (str): Path to the folder to store processed videos. Defaults to '../data/processed_videos/'.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    def frames_to_video(sampled_frames, output_path, fps=frames_per_video):\n",
    "        height, width, _ = sampled_frames[0].shape\n",
    "        fourcc = cv2.VideoWriter.fourcc(*'mp4v')\n",
    "        video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        for frame in sampled_frames:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            video.write(frame_rgb)\n",
    "\n",
    "        video.release()\n",
    "\n",
    "    output_folder = os.path.dirname('../data/processed_videos/')\n",
    "\n",
    "    if os.path.exists(output_folder):\n",
    "        shutil.rmtree(output_folder)\n",
    "\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "    for i, sampled_frames in enumerate(X):\n",
    "            video_path = f'../data/processed_videos/processed_{i}.mp4'\n",
    "            frames_to_video(sampled_frames, video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_csv(list_of_dataframes):\n",
    "    output_folder = os.path.dirname('../data/csv/')\n",
    "\n",
    "    # Remove the folder if it exists\n",
    "    if os.path.exists(output_folder):\n",
    "        shutil.rmtree(output_folder)\n",
    "\n",
    "    os.makedirs(output_folder)  # Recreate the folder\n",
    "\n",
    "    for i, dataframe in enumerate(list_of_dataframes):\n",
    "        file_path = f'{output_folder}/dataframe_{i}.csv'\n",
    "        dataframe.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create Train / Validation split #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_cat_train, y_cat_val = train_test_split(X,\n",
    "                                                          y_cat,\n",
    "                                                          train_size=train_size,\n",
    "                                                          random_state=1,\n",
    "                                                          stratify=y_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Video augmentation for increased data set size #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame_params(frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Generate random parameters for image augmentation.\n",
    "\n",
    "    Args:\n",
    "    - frame_width (int): Width of the frame.\n",
    "    - frame_height (int): Height of the frame.\n",
    "\n",
    "    Returns:\n",
    "    Variables containing randomly generated parameters for frame augmentation.\n",
    "        - angle (float): Random rotation between 0 and 15 degrees.\n",
    "        - flip (float): Random value for horizontal mirroring.\n",
    "        - x_trans (int): Random translation along the x-axis between -20 and 20 pixels.\n",
    "        - y_trans (int): Random translation along the y-axis between -20 and 20 pixels.\n",
    "        - scale (float): Random zoom factor between 0.8 and 1.2.\n",
    "        - crop_size (int): Random size for cropping within the frame.\n",
    "        - alpha (float): Random value for brightness and contrast adjustment between 0.7 and 1.3.\n",
    "        - beta (int): Random value for brightness and contrast adjustment between -20 and 20.\n",
    "    \"\"\"\n",
    "    # Random rotation between -15 and 15 degrees\n",
    "    angle = np.random.uniform(0, 15)\n",
    "    # Random horizontal mirroring\n",
    "    flip = np.random.rand()\n",
    "    # Random translation\n",
    "    x_trans = np.random.randint(-20, 20)\n",
    "    y_trans = np.random.randint(-20, 20)\n",
    "    # Random zoom\n",
    "    scale = np.random.uniform(0.8, 1.2)\n",
    "    # Random cropping (with centralized region)\n",
    "    crop_size = np.random.randint(0.8 * min(frame_width, frame_height), min(frame_width, frame_height))\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    alpha = np.random.uniform(0.7, 1.3)\n",
    "    beta = np.random.randint(-20, 20)\n",
    "\n",
    "    return angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame(frame, angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta, target_size):\n",
    "    \"\"\"\n",
    "    Apply various random transformations to an input image/frame.\n",
    "\n",
    "    Args:\n",
    "    - frame (numpy.ndarray): Input image/frame to be augmented.\n",
    "    - angle (float): Angle for random rotation.\n",
    "    - flip (float): Value for horizontal flipping (50% chance).\n",
    "    - x_trans (int): Random translation along the x-axis.\n",
    "    - y_trans (int): Random translation along the y-axis.\n",
    "    - scale (float): Random zoom factor.\n",
    "    - crop_size (int): Random size for cropping within the frame.\n",
    "    - alpha (float): Value for brightness and contrast adjustment.\n",
    "    - beta (int): Value for brightness and contrast adjustment.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Augmented image/frame after applying random transformations.\n",
    "    \"\"\"\n",
    "    # Random rotation by an angle\n",
    "    rows, cols, _ = frame.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows))\n",
    "    # Horizontal flipping\n",
    "    if flip > 0.5:  # 50% chance of flipping\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    # Random translation\n",
    "    M = np.float32([[1, 0, x_trans], [0, 1, y_trans]]) # type: ignore\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows)) # type: ignore\n",
    "    # Random zoom\n",
    "    frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "    # Random cropping (with centralized region)\n",
    "    x = int((rows - crop_size) / 2)\n",
    "    y = int((cols - crop_size) / 2)\n",
    "    frame = frame[x:x + crop_size, y:y + crop_size]\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    # Resize frame back to height 150, width 150\n",
    "    frame = cv2.resize(frame, target_size)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_data(X, frames_per_video):\n",
    "    X_temp = np.empty((len(X), frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "    frame_height = X.shape[2]\n",
    "    frame_width = X.shape[3]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        angle, flip, x_trans, y_trans,\\\n",
    "        scale, crop_size, alpha, beta = augment_frame_params(frame_height, frame_width)\n",
    "        for j in range(frames_per_video):\n",
    "            sampled_frame = X[i][j]\n",
    "            aug_frame = augment_frame(sampled_frame,\n",
    "                                      angle,\n",
    "                                      flip,\n",
    "                                      x_trans,\n",
    "                                      y_trans,\n",
    "                                      scale,\n",
    "                                      crop_size,\n",
    "                                      alpha,\n",
    "                                      beta,\n",
    "                                      target_size)\n",
    "            X_temp[i][j] = aug_frame\n",
    "\n",
    "    return X_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a copy of preprocessed X and categoried y\n",
    "X_aug = X_train.copy()\n",
    "y_aug = y_cat_train.copy()\n",
    "\n",
    "# Multiply dataset by defined param\n",
    "for _ in range(number_of_augmentations):\n",
    "    X_temp = multiply_data(X_train, frames_per_video)\n",
    "    # Returns X_aug with shape (n * 219, 10, 150, 150, 3)\n",
    "    X_aug = np.concatenate((X_aug, X_temp), axis=0)\n",
    "    # Returns y_aug with shape (n * 219, 20)\n",
    "    y_aug = np.concatenate((y_aug, y_cat_train), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8) Testing output, generating videos and CSV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_aug has been initialized with Shape (210, 20, 480, 480, 3)!\n",
      "✅ y_aug has been initialized with Shape (210, 15)!\n",
      "\n",
      "✅ X_val has been initialized with Shape (90, 20, 480, 480, 3)!\n",
      "✅ y_cat_val has been initialized with Shape (90, 15)!\n"
     ]
    }
   ],
   "source": [
    "if X_aug.shape == ((number_of_augmentations + 1) * len(X_train), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X_aug has been initialized with Shape {X_aug.shape}!')\n",
    "else:\n",
    "    print('❌ X_aug has not been initialized properly!')\n",
    "\n",
    "if y_aug.shape == ((number_of_augmentations + 1) * len(y_cat_train), n_classes):\n",
    "    print(f'✅ y_aug has been initialized with Shape {y_aug.shape}!')\n",
    "else:\n",
    "    print('❌ y_aug has not been initialized properly!')\n",
    "\n",
    "print()\n",
    "\n",
    "if X_val.shape == (round(len(X) * (1 - train_size)), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X_val has been initialized with Shape {X_val.shape}!')\n",
    "else:\n",
    "    print('❌ X_val has not been initialized properly!')\n",
    "\n",
    "if y_cat_val.shape == (round(len(y_cat) * (1 - train_size)), n_classes):\n",
    "    print(f'✅ y_cat_val has been initialized with Shape {y_cat_val.shape}!')\n",
    "else:\n",
    "    print('❌ y_cat_val has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_processed_videos(X_aug)\n",
    "# list_of_dataframes = [wlas_df, features_df, selected_df]\n",
    "# generate_csv(list_of_dataframes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SignFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
