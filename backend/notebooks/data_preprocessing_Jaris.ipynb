{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from PIL import Image\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 20 words were selected based on the amount of samples available\n",
    "# selected_words = [\n",
    "#     'like', 'work', 'play', 'take', 'call',\n",
    "#     'go', 'study', 'give', 'write', 'yesterday',\n",
    "#     'far', 'hot', 'cold', 'good', 'bad',\n",
    "#     'computer', 'apple', 'doctor', 'family', 'dog'\n",
    "# ]\n",
    "selected_words = ['work','study', 'write', 'hot', 'cold', 'family']\n",
    "n_classes = len(selected_words)\n",
    "\n",
    "# Absolute main path\n",
    "main_path = '../data/'\n",
    "\n",
    "# Frame sampling parameters\n",
    "frames_per_video = 10\n",
    "target_size = (150, 150)\n",
    "\n",
    "# Dataset multiplier\n",
    "number_of_augmentations = 3\n",
    "\n",
    "# Train split parameters\n",
    "train_size = 0.7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute main path\n",
    "# main_path = '../data/'\n",
    "\n",
    "# Read JSON file into a DataFrame with unprocessed instance col\n",
    "wlas_df = pd.read_json(main_path + 'WLASL_v0.3.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids of the current instance\n",
    "\n",
    "    Input: instance json list\n",
    "    Output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_list = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_list.append(video_id)\n",
    "    return videos_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_features(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids and url or any other featrue of the current instance\n",
    "\n",
    "    input: instance json list\n",
    "    output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_ids = []\n",
    "    videos_urls = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        video_url = ins['url']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_ids.append(video_id)\n",
    "            videos_urls.append(video_url)\n",
    "    return videos_ids, videos_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open JSON file (read only)\n",
    "with open(main_path+'WLASL_v0.3.json', 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "instance_json = json.loads(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "      <th>videos_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "      <td>[69241, 07069, 07068, 07070, 07099, 07074]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[69302, 65539, 17710, 17733, 65540, 17734, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[12328, 12312, 12311, 12338, 12313, 12314, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[05728, 05749, 05750, 05729, 05730, 65167, 057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[09848, 09869, 09849, 09850, 09851, 65328, 09854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>washington</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62393, 62394, 62395, 62396, 62398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>waterfall</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62488, 62489, 62490, 62492, 62493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>weigh</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62782, 62783, 62785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>[{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[63044, 63046, 63047, 63050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>whistle</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[63186, 63188, 63190]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gloss                                          instances  \\\n",
       "0           book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...   \n",
       "1          drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...   \n",
       "2       computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "3         before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "4          chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "...          ...                                                ...   \n",
       "1995  washington  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1996   waterfall  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1997       weigh  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1998  wheelchair  [{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...   \n",
       "1999     whistle  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "\n",
       "                                             videos_ids  \n",
       "0            [69241, 07069, 07068, 07070, 07099, 07074]  \n",
       "1     [69302, 65539, 17710, 17733, 65540, 17734, 177...  \n",
       "2     [12328, 12312, 12311, 12338, 12313, 12314, 123...  \n",
       "3     [05728, 05749, 05750, 05729, 05730, 65167, 057...  \n",
       "4     [09848, 09869, 09849, 09850, 09851, 65328, 09854]  \n",
       "...                                                 ...  \n",
       "1995                [62393, 62394, 62395, 62396, 62398]  \n",
       "1996                [62488, 62489, 62490, 62492, 62493]  \n",
       "1997                              [62782, 62783, 62785]  \n",
       "1998                       [63044, 63046, 63047, 63050]  \n",
       "1999                              [63186, 63188, 63190]  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get available video ids for all rows in wlas_df and add to new col 'videos_id'\n",
    "wlas_df['videos_ids'] = wlas_df['instances'].apply(get_videos_ids)\n",
    "wlas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>69241</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>07069</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>07068</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>07070</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>07099</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63047</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/5/5233.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63050</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/wheelcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63186</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63188</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/9/9961.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63190</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/whistle.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word video_id                                                url\n",
       "index                                                                        \n",
       "0            book    69241       http://aslbricks.org/New/ASL-Videos/book.mp4\n",
       "1            book    07069  https://signstock.blob.core.windows.net/signsc...\n",
       "2            book    07068  https://s3-us-west-1.amazonaws.com/files.start...\n",
       "3            book    07070  https://media.asldeafined.com/vocabulary/14666...\n",
       "4            book    07099     http://www.aslsearch.com/signs/videos/book.mp4\n",
       "...           ...      ...                                                ...\n",
       "11975  wheelchair    63047  https://www.signingsavvy.com/signs/mp4/5/5233.mp4\n",
       "11976  wheelchair    63050  http://www.aslsearch.com/signs/videos/wheelcha...\n",
       "11977     whistle    63186  https://media.spreadthesign.com/video/mp4/13/9...\n",
       "11978     whistle    63188  https://www.signingsavvy.com/signs/mp4/9/9961.mp4\n",
       "11979     whistle    63190  http://www.aslsearch.com/signs/videos/whistle.mp4\n",
       "\n",
       "[11980 rows x 3 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate DataFrame for available information in each instance\n",
    "features_df = pd.DataFrame(columns=['word', 'video_id', 'url'])\n",
    "\n",
    "for row in wlas_df.iterrows():\n",
    "    # Extract ids and urls for each row\n",
    "    ids, urls = get_json_features(row[1][1])\n",
    "    # Initialize a list matching the length (n) of found ids containing the word\n",
    "    word = [row[1][0]] * len(ids)\n",
    "    # Using zip to create new df with:\n",
    "    # n * word in gloss col (e.g. 6 * book)\n",
    "    # Unique id and url in ids and url col respectively\n",
    "    df = pd.DataFrame(list(zip(word, ids, urls)), columns = features_df.columns)\n",
    "    # Append temporary df to feature_df\n",
    "    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "# Renaming index col to index\n",
    "features_df.index.name = 'index'\n",
    "features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Define 20 target classes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = features_df[features_df['word'].isin(selected_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "      <th>video_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hot</td>\n",
       "      <td>69368</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/hot.mp4</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hot</td>\n",
       "      <td>28125</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/heat2.mp4</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hot</td>\n",
       "      <td>28108</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hot</td>\n",
       "      <td>28109</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hot</td>\n",
       "      <td>28110</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>cold</td>\n",
       "      <td>11628</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14668...</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>cold</td>\n",
       "      <td>11621</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/3...</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>cold</td>\n",
       "      <td>11633</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/22/2275...</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>cold</td>\n",
       "      <td>11634</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/22/2286...</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cold</td>\n",
       "      <td>11635</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/7/7159.mp4</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    word video_id                                                url  \\\n",
       "0    hot    69368        http://aslbricks.org/New/ASL-Videos/hot.mp4   \n",
       "1    hot    28125    http://www.aslsearch.com/signs/videos/heat2.mp4   \n",
       "2    hot    28108  https://s3-us-west-1.amazonaws.com/files.start...   \n",
       "3    hot    28109  https://signstock.blob.core.windows.net/signsc...   \n",
       "4    hot    28110  https://signstock.blob.core.windows.net/signsc...   \n",
       "..   ...      ...                                                ...   \n",
       "58  cold    11628  https://media.asldeafined.com/vocabulary/14668...   \n",
       "59  cold    11621  https://media.spreadthesign.com/video/mp4/13/3...   \n",
       "60  cold    11633  https://www.signingsavvy.com/signs/mp4/22/2275...   \n",
       "61  cold    11634  https://www.signingsavvy.com/signs/mp4/22/2286...   \n",
       "62  cold    11635  https://www.signingsavvy.com/signs/mp4/7/7159.mp4   \n",
       "\n",
       "    video_length  \n",
       "0           57.0  \n",
       "1           71.0  \n",
       "2           69.0  \n",
       "3           59.0  \n",
       "4           35.0  \n",
       "..           ...  \n",
       "58          89.0  \n",
       "59          58.0  \n",
       "60          69.0  \n",
       "61          67.0  \n",
       "62          33.0  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for video_id in selected_df['video_id']:\n",
    "    if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "        cap = cv2.VideoCapture(f'{main_path}videos/{video_id}.mp4')\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        selected_df.loc[selected_df['video_id'] == video_id, ['video_length']] = int(length)\n",
    "    pass\n",
    "\n",
    "selected_df = selected_df.reset_index(drop=True)\n",
    "input_length = len(selected_df)\n",
    "selected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Defining the Input/Features: X #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty array of desired shape\n",
    "X = np.empty((input_length, frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Function to perform frame sampling\n",
    "def sample_frames(video_path, frames_per_video, total_frames):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_indices = []\n",
    "\n",
    "    while len(set(frame_indices)) != frames_per_video:\n",
    "        frame_indices = sorted(np.random.uniform(0, total_frames-5, frames_per_video).astype(int))\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_counter in frame_indices:\n",
    "                # Resize frame to required size\n",
    "                frame = cv2.resize(frame, target_size)\n",
    "                # CV2 output BGR -> converting to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Append to list of frames\n",
    "                frames.append(frame_rgb)\n",
    "\n",
    "            frame_counter += 1\n",
    "\n",
    "            if len(frames) == frames_per_video:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "for i, row in selected_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    total_frames = row['video_length']\n",
    "    video_path = f'../data/videos/{video_id}.mp4'\n",
    "\n",
    "    sampled_frames = sample_frames(video_path, frames_per_video, total_frames)\n",
    "\n",
    "    # Assign sampled frames to results array\n",
    "    X[i] = np.array(sampled_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X has been initialized with Shape (63, 10, 150, 150, 3)!\n"
     ]
    }
   ],
   "source": [
    "if X.shape == (len(selected_df), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X has been initialized with Shape {X.shape}!')\n",
    "else:\n",
    "    print('❌ X has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Defining the Output/Target: y #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "selected_df['encoded_word'] = label_encoder.fit_transform(selected_df['word'])\n",
    "y_cat = tf.keras.utils.to_categorical(selected_df['encoded_word'], num_classes=n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ y has been initialized with Shape (63, 6)!\n"
     ]
    }
   ],
   "source": [
    "if y_cat.shape == (input_length, n_classes):\n",
    "    print(f'✅ y has been initialized with Shape {y_cat.shape}!')\n",
    "else:\n",
    "    print('❌ y has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Restore sampled frames into .mp4 files #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_video(sampled_frames, output_path, fps=frames_per_video):\n",
    "    height, width, _ = sampled_frames[0].shape\n",
    "    fourcc = cv2.VideoWriter.fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame in sampled_frames:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        video.write(frame_rgb)\n",
    "\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_processed_videos(X):\n",
    "    output_folder = os.path.dirname('../data/processed_videos/')\n",
    "\n",
    "    # Remove the folder if it exists\n",
    "    if os.path.exists(output_folder):\n",
    "        shutil.rmtree(output_folder)\n",
    "\n",
    "    os.makedirs(output_folder)  # Recreate the folder\n",
    "\n",
    "    # 'X' is a 5-dimensional numpy array with shape (num_videos, frames_per_video, height, width, channels)\n",
    "    for i, sampled_frames in enumerate(X):\n",
    "            video_path = f'../data/processed_videos/processed_{i}.mp4'  # Output path for each video\n",
    "            frames_to_video(sampled_frames, video_path)  # Convert frames to video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create Train / Validation split #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_cat_train, y_cat_val = train_test_split(X,\n",
    "                                                          y_cat,\n",
    "                                                          train_size=train_size,\n",
    "                                                          random_state=1,\n",
    "                                                          stratify=y_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Video augmentation for increased data set size #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame_params(frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Generate random parameters for image augmentation.\n",
    "\n",
    "    Args:\n",
    "    - frame_width (int): Width of the frame.\n",
    "    - frame_height (int): Height of the frame.\n",
    "\n",
    "    Returns:\n",
    "    Variables containing randomly generated parameters for frame augmentation.\n",
    "        - angle (float): Random rotation between 0 and 15 degrees.\n",
    "        - flip (float): Random value for horizontal mirroring.\n",
    "        - x_trans (int): Random translation along the x-axis between -20 and 20 pixels.\n",
    "        - y_trans (int): Random translation along the y-axis between -20 and 20 pixels.\n",
    "        - scale (float): Random zoom factor between 0.8 and 1.2.\n",
    "        - crop_size (int): Random size for cropping within the frame.\n",
    "        - alpha (float): Random value for brightness and contrast adjustment between 0.7 and 1.3.\n",
    "        - beta (int): Random value for brightness and contrast adjustment between -20 and 20.\n",
    "    \"\"\"\n",
    "    # Random rotation between -15 and 15 degrees\n",
    "    angle = np.random.uniform(0, 15)\n",
    "    # Random horizontal mirroring\n",
    "    flip = np.random.rand()\n",
    "    # Random translation\n",
    "    x_trans = np.random.randint(-20, 20)\n",
    "    y_trans = np.random.randint(-20, 20)\n",
    "    # Random zoom\n",
    "    scale = np.random.uniform(0.8, 1.2)\n",
    "    # Random cropping (with centralized region)\n",
    "    crop_size = np.random.randint(0.8 * min(frame_width, frame_height), min(frame_width, frame_height))\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    alpha = np.random.uniform(0.7, 1.3)\n",
    "    beta = np.random.randint(-20, 20)\n",
    "\n",
    "    return angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame(frame, angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta, target_size):\n",
    "    \"\"\"\n",
    "    Apply various random transformations to an input image/frame.\n",
    "\n",
    "    Args:\n",
    "    - frame (numpy.ndarray): Input image/frame to be augmented.\n",
    "    - angle (float): Angle for random rotation.\n",
    "    - flip (float): Value for horizontal flipping (50% chance).\n",
    "    - x_trans (int): Random translation along the x-axis.\n",
    "    - y_trans (int): Random translation along the y-axis.\n",
    "    - scale (float): Random zoom factor.\n",
    "    - crop_size (int): Random size for cropping within the frame.\n",
    "    - alpha (float): Value for brightness and contrast adjustment.\n",
    "    - beta (int): Value for brightness and contrast adjustment.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Augmented image/frame after applying random transformations.\n",
    "    \"\"\"\n",
    "    # Random rotation by an angle\n",
    "    rows, cols, _ = frame.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows))\n",
    "    # Horizontal flipping\n",
    "    if flip > 0.5:  # 50% chance of flipping\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    # Random translation\n",
    "    M = np.float32([[1, 0, x_trans], [0, 1, y_trans]]) # type: ignore\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows)) # type: ignore\n",
    "    # Random zoom\n",
    "    frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "    # Random cropping (with centralized region)\n",
    "    x = int((rows - crop_size) / 2)\n",
    "    y = int((cols - crop_size) / 2)\n",
    "    frame = frame[x:x + crop_size, y:y + crop_size]\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    # Resize frame back to height 150, width 150\n",
    "    frame = cv2.resize(frame, target_size)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_data(X, frames_per_video):\n",
    "    X_temp = np.empty((len(X), frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "    frame_height = X.shape[2]\n",
    "    frame_width = X.shape[3]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        angle, flip, x_trans, y_trans,\\\n",
    "        scale, crop_size, alpha, beta = augment_frame_params(frame_height, frame_width)\n",
    "        for j in range(frames_per_video):\n",
    "            sampled_frame = X[i][j]\n",
    "            aug_frame = augment_frame(sampled_frame,\n",
    "                                      angle,\n",
    "                                      flip,\n",
    "                                      x_trans,\n",
    "                                      y_trans,\n",
    "                                      scale,\n",
    "                                      crop_size,\n",
    "                                      alpha,\n",
    "                                      beta,\n",
    "                                      target_size)\n",
    "            X_temp[i][j] = aug_frame\n",
    "\n",
    "    return X_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a copy of preprocessed X and categoried y\n",
    "X_aug = X_train.copy()\n",
    "y_aug = y_cat_train.copy()\n",
    "\n",
    "# Multiply dataset by defined param\n",
    "for _ in range(number_of_augmentations):\n",
    "    X_temp = multiply_data(X_train, frames_per_video)\n",
    "    # Returns X_aug with shape (n * 219, 10, 150, 150, 3)\n",
    "    X_aug = np.concatenate((X_aug, X_temp), axis=0)\n",
    "    # Returns y_aug with shape (n * 219, 20)\n",
    "    y_aug = np.concatenate((y_aug, y_cat_train), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7) Testing output and generating videos #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_aug has been initialized with Shape (176, 10, 150, 150, 3)!\n",
      "✅ y_aug has been initialized with Shape (176, 6)!\n",
      "\n",
      "✅ X_val has been initialized with Shape (19, 10, 150, 150, 3)!\n",
      "✅ y_cat_val has been initialized with Shape (19, 6)!\n"
     ]
    }
   ],
   "source": [
    "if X_aug.shape == ((number_of_augmentations + 1) * len(X_train), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X_aug has been initialized with Shape {X_aug.shape}!')\n",
    "else:\n",
    "    print('❌ X_aug has not been initialized properly!')\n",
    "\n",
    "if y_aug.shape == ((number_of_augmentations + 1) * len(y_cat_train), n_classes):\n",
    "    print(f'✅ y_aug has been initialized with Shape {y_aug.shape}!')\n",
    "else:\n",
    "    print('❌ y_aug has not been initialized properly!')\n",
    "\n",
    "print()\n",
    "\n",
    "if X_val.shape == (round(len(X) * (1 - train_size)), frames_per_video, *target_size, 3):\n",
    "    print(f'✅ X_val has been initialized with Shape {X_val.shape}!')\n",
    "else:\n",
    "    print('❌ X_val has not been initialized properly!')\n",
    "\n",
    "if y_cat_val.shape == (round(len(y_cat) * (1 - train_size)), n_classes):\n",
    "    print(f'✅ y_cat_val has been initialized with Shape {y_cat_val.shape}!')\n",
    "else:\n",
    "    print('❌ y_cat_val has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_processed_videos(X_aug)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SignFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
