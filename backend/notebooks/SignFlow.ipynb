{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load Data #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute main path\n",
    "main_path = '../data/'\n",
    "\n",
    "# Read JSON file into a DataFrame with unprocessed instance col\n",
    "wlas_df = pd.read_json(main_path + 'WLASL_v0.3.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos_ids(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids of the current instance\n",
    "\n",
    "    Input: instance json list\n",
    "    Output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_list = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_list.append(video_id)\n",
    "    return videos_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json_features(json_list):\n",
    "    \"\"\"\n",
    "    function to check if the video id is available in the dataset\n",
    "    and return the viedos ids and url or any other featrue of the current instance\n",
    "\n",
    "    input: instance json list\n",
    "    output: list of videos_ids\n",
    "    \"\"\"\n",
    "    videos_ids = []\n",
    "    videos_urls = []\n",
    "    for ins in json_list:\n",
    "        video_id = ins['video_id']\n",
    "        video_url = ins['url']\n",
    "        if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "            videos_ids.append(video_id)\n",
    "            videos_urls.append(video_url)\n",
    "    return videos_ids, videos_urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open JSON file (read only)\n",
    "with open(main_path+'WLASL_v0.3.json', 'r') as data_file:\n",
    "    json_data = data_file.read()\n",
    "\n",
    "instance_json = json.loads(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gloss</th>\n",
       "      <th>instances</th>\n",
       "      <th>videos_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>[{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...</td>\n",
       "      <td>[69241, 07069, 07068, 07070, 07099, 07074]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink</td>\n",
       "      <td>[{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[69302, 65539, 17710, 17733, 65540, 17734, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[12328, 12312, 12311, 12338, 12313, 12314, 123...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>before</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[05728, 05749, 05750, 05729, 05730, 65167, 057...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chair</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[09848, 09869, 09849, 09850, 09851, 65328, 09854]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>washington</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62393, 62394, 62395, 62396, 62398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>waterfall</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62488, 62489, 62490, 62492, 62493]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>weigh</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[62782, 62783, 62785]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>[{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...</td>\n",
       "      <td>[63044, 63046, 63047, 63050]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>whistle</td>\n",
       "      <td>[{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...</td>\n",
       "      <td>[63186, 63188, 63190]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           gloss                                          instances  \\\n",
       "0           book  [{'bbox': [385, 37, 885, 720], 'fps': 25, 'fra...   \n",
       "1          drink  [{'bbox': [551, 68, 1350, 1080], 'fps': 25, 'f...   \n",
       "2       computer  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "3         before  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "4          chair  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "...          ...                                                ...   \n",
       "1995  washington  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1996   waterfall  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1997       weigh  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "1998  wheelchair  [{'bbox': [415, 86, 1811, 1080], 'fps': 25, 'f...   \n",
       "1999     whistle  [{'bbox': [0, 0, 360, 240], 'fps': 25, 'frame_...   \n",
       "\n",
       "                                             videos_ids  \n",
       "0            [69241, 07069, 07068, 07070, 07099, 07074]  \n",
       "1     [69302, 65539, 17710, 17733, 65540, 17734, 177...  \n",
       "2     [12328, 12312, 12311, 12338, 12313, 12314, 123...  \n",
       "3     [05728, 05749, 05750, 05729, 05730, 65167, 057...  \n",
       "4     [09848, 09869, 09849, 09850, 09851, 65328, 09854]  \n",
       "...                                                 ...  \n",
       "1995                [62393, 62394, 62395, 62396, 62398]  \n",
       "1996                [62488, 62489, 62490, 62492, 62493]  \n",
       "1997                              [62782, 62783, 62785]  \n",
       "1998                       [63044, 63046, 63047, 63050]  \n",
       "1999                              [63186, 63188, 63190]  \n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get available video ids for all rows in wlas_df and add to new col 'videos_id'\n",
    "wlas_df['videos_ids'] = wlas_df['instances'].apply(get_videos_ids)\n",
    "wlas_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>69241</td>\n",
       "      <td>http://aslbricks.org/New/ASL-Videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>book</td>\n",
       "      <td>07069</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>book</td>\n",
       "      <td>07068</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book</td>\n",
       "      <td>07070</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14666...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>07099</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/book.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11975</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63047</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/5/5233.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>wheelchair</td>\n",
       "      <td>63050</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/wheelcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11977</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63186</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11978</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63188</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/9/9961.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11979</th>\n",
       "      <td>whistle</td>\n",
       "      <td>63190</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/whistle.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11980 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word video_id                                                url\n",
       "index                                                                        \n",
       "0            book    69241       http://aslbricks.org/New/ASL-Videos/book.mp4\n",
       "1            book    07069  https://signstock.blob.core.windows.net/signsc...\n",
       "2            book    07068  https://s3-us-west-1.amazonaws.com/files.start...\n",
       "3            book    07070  https://media.asldeafined.com/vocabulary/14666...\n",
       "4            book    07099     http://www.aslsearch.com/signs/videos/book.mp4\n",
       "...           ...      ...                                                ...\n",
       "11975  wheelchair    63047  https://www.signingsavvy.com/signs/mp4/5/5233.mp4\n",
       "11976  wheelchair    63050  http://www.aslsearch.com/signs/videos/wheelcha...\n",
       "11977     whistle    63186  https://media.spreadthesign.com/video/mp4/13/9...\n",
       "11978     whistle    63188  https://www.signingsavvy.com/signs/mp4/9/9961.mp4\n",
       "11979     whistle    63190  http://www.aslsearch.com/signs/videos/whistle.mp4\n",
       "\n",
       "[11980 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create separate DataFrame for available information in each instance\n",
    "features_df = pd.DataFrame(columns=['word', 'video_id', 'url'])\n",
    "\n",
    "for row in wlas_df.iterrows():\n",
    "    # Extract ids and urls for each row\n",
    "    ids, urls = get_json_features(row[1][1])\n",
    "    # Initialize a list matching the length (n) of found ids containing the word\n",
    "    word = [row[1][0]] * len(ids)\n",
    "    # Using zip to create new df with:\n",
    "    # n * word in gloss col (e.g. 6 * book)\n",
    "    # Unique id and url in ids and url col respectively\n",
    "    df = pd.DataFrame(list(zip(word, ids, urls)), columns = features_df.columns)\n",
    "    # Append temporary df to feature_df\n",
    "    features_df = pd.concat([features_df, df], ignore_index=True)\n",
    "\n",
    "# Renaming index col to index\n",
    "features_df.index.name = 'index'\n",
    "features_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Define 20 target classes #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 20 words were selected based on the amount of samples available\n",
    "\n",
    "selected_words = [\n",
    "    'like', 'work', 'play', 'take', 'call',\n",
    "    'go', 'study', 'give', 'write', 'yesterday',\n",
    "    'far', 'hot', 'cold', 'good', 'bad',\n",
    "    'computer', 'apple', 'doctor', 'family', 'dog'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = features_df[features_df['word'].isin(selected_words)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>video_id</th>\n",
       "      <th>url</th>\n",
       "      <th>video_length</th>\n",
       "      <th>encoded_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>computer</td>\n",
       "      <td>12328</td>\n",
       "      <td>https://www.signingsavvy.com/signs/mp4/6/6326.mp4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>computer</td>\n",
       "      <td>12312</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer</td>\n",
       "      <td>12311</td>\n",
       "      <td>https://media.spreadthesign.com/video/mp4/13/5...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>computer</td>\n",
       "      <td>12338</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/computer...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>computer</td>\n",
       "      <td>12313</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>good</td>\n",
       "      <td>25076</td>\n",
       "      <td>http://www.aslsearch.com/signs/videos/good.mp4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>good</td>\n",
       "      <td>25067</td>\n",
       "      <td>https://s3-us-west-1.amazonaws.com/files.start...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>good</td>\n",
       "      <td>25068</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>good</td>\n",
       "      <td>25069</td>\n",
       "      <td>https://signstock.blob.core.windows.net/signsc...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>good</td>\n",
       "      <td>25070</td>\n",
       "      <td>https://media.asldeafined.com/vocabulary/14685...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word video_id                                                url  \\\n",
       "0    computer    12328  https://www.signingsavvy.com/signs/mp4/6/6326.mp4   \n",
       "1    computer    12312  https://s3-us-west-1.amazonaws.com/files.start...   \n",
       "2    computer    12311  https://media.spreadthesign.com/video/mp4/13/5...   \n",
       "3    computer    12338  http://www.aslsearch.com/signs/videos/computer...   \n",
       "4    computer    12313  https://s3-us-west-1.amazonaws.com/files.start...   \n",
       "..        ...      ...                                                ...   \n",
       "214      good    25076     http://www.aslsearch.com/signs/videos/good.mp4   \n",
       "215      good    25067  https://s3-us-west-1.amazonaws.com/files.start...   \n",
       "216      good    25068  https://signstock.blob.core.windows.net/signsc...   \n",
       "217      good    25069  https://signstock.blob.core.windows.net/signsc...   \n",
       "218      good    25070  https://media.asldeafined.com/vocabulary/14685...   \n",
       "\n",
       "     video_length  encoded_word  \n",
       "0            88.0             4  \n",
       "1           101.0             4  \n",
       "2            72.0             4  \n",
       "3           107.0             4  \n",
       "4            81.0             4  \n",
       "..            ...           ...  \n",
       "214          86.0            11  \n",
       "215          74.0            11  \n",
       "216          60.0            11  \n",
       "217          21.0            11  \n",
       "218          52.0            11  \n",
       "\n",
       "[219 rows x 5 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for video_id in selected_df['video_id']:\n",
    "    if os.path.exists(f'{main_path}videos/{video_id}.mp4'):\n",
    "        cap = cv2.VideoCapture(f'{main_path}videos/{video_id}.mp4')\n",
    "        length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        selected_df.loc[selected_df['video_id'] == video_id, ['video_length']] = int(length)\n",
    "    pass\n",
    "\n",
    "selected_df = selected_df.reset_index(drop=True)\n",
    "selected_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Defining the Input/Features: X #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame sampling parameters\n",
    "frames_per_video = 10\n",
    "target_size = (150, 150)\n",
    "# Initialize empty array of desired shape\n",
    "X = np.empty((219, frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "\n",
    "# Function to perform frame sampling\n",
    "def sample_frames(video_path, frames_per_video, total_frames):\n",
    "    frames = []\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_indices = []\n",
    "\n",
    "    while len(set(frame_indices)) != frames_per_video:\n",
    "        frame_indices = sorted(np.random.uniform(0, total_frames-5, frames_per_video).astype(int))\n",
    "\n",
    "    frame_counter = 0\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if frame_counter in frame_indices:\n",
    "                # Resize frame to required size\n",
    "                frame = cv2.resize(frame, target_size)\n",
    "                # CV2 output BGR -> converting to RGB\n",
    "                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                # Append to list of frames\n",
    "                frames.append(frame_rgb)\n",
    "\n",
    "            frame_counter += 1\n",
    "\n",
    "            if len(frames) == frames_per_video:\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        cap.release()\n",
    "\n",
    "    return frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[h264 @ 0x55a86b6bb080] Invalid NAL unit size (745 > 472).\n",
      "[h264 @ 0x55a86b6bb080] Error splitting the input into NAL units.\n",
      "[mov,mp4,m4a,3gp,3g2,mj2 @ 0x55a879e44cc0] stream 1, offset 0x3b468: partial file\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "for i, row in selected_df.iterrows():\n",
    "    video_id = row['video_id']\n",
    "    total_frames = row['video_length']\n",
    "    video_path = f'../data/videos/{video_id}.mp4'\n",
    "\n",
    "    sampled_frames = sample_frames(video_path, frames_per_video, total_frames)\n",
    "\n",
    "    # Assign sampled frames to results array\n",
    "    X[i] = np.array(sampled_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X has been initialized with Shape (219, 10, 150, 150, 3)!\n"
     ]
    }
   ],
   "source": [
    "if X.shape == (219, 10, 150, 150, 3):\n",
    "    print(f'✅ X has been initialized with Shape {X.shape}!')\n",
    "else:\n",
    "    print('❌ X has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Defining the Output/Target: y #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "selected_df['encoded_word'] = label_encoder.fit_transform(selected_df['word'])\n",
    "y_cat = tf.keras.utils.to_categorical(selected_df['encoded_word'], num_classes=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ y has been initialized with Shape (219, 20)!\n"
     ]
    }
   ],
   "source": [
    "if y_cat.shape == (219, 20):\n",
    "    print(f'✅ y has been initialized with Shape {y_cat.shape}!')\n",
    "else:\n",
    "    print('❌ y has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Restore sampled frames into .mp4 files #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_to_video(sampled_frames, output_path, fps=10):\n",
    "    if not os.path.exists(os.path.dirname(output_path)):\n",
    "        os.makedirs(os.path.dirname(output_path))\n",
    "\n",
    "    height, width, _ = sampled_frames[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for frame in sampled_frames:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        video.write(frame_rgb)\n",
    "\n",
    "    video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_processed_videos(X):\n",
    "    # 'X' is a 5-dimensional numpy array with shape (num_videos, frames_per_video, height, width, channels)\n",
    "    for i, sampled_frames in enumerate(X):\n",
    "            video_path = f'../data/processed_videos/processed_{i}.mp4'  # Output path for each video\n",
    "            frames_to_video(sampled_frames, video_path)  # Convert frames to video\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Video augmentation for increased data set size #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame_params(frame_width, frame_height):\n",
    "    \"\"\"\n",
    "    Generate random parameters for image augmentation.\n",
    "\n",
    "    Args:\n",
    "    - frame_width (int): Width of the frame.\n",
    "    - frame_height (int): Height of the frame.\n",
    "\n",
    "    Returns:\n",
    "    Variables containing randomly generated parameters for frame augmentation.\n",
    "        - angle (float): Random rotation between 0 and 15 degrees.\n",
    "        - flip (float): Random value for horizontal mirroring.\n",
    "        - x_trans (int): Random translation along the x-axis between -20 and 20 pixels.\n",
    "        - y_trans (int): Random translation along the y-axis between -20 and 20 pixels.\n",
    "        - scale (float): Random zoom factor between 0.8 and 1.2.\n",
    "        - crop_size (int): Random size for cropping within the frame.\n",
    "        - alpha (float): Random value for brightness and contrast adjustment between 0.7 and 1.3.\n",
    "        - beta (int): Random value for brightness and contrast adjustment between -20 and 20.\n",
    "    \"\"\"\n",
    "    # Random rotation between -15 and 15 degrees\n",
    "    angle = np.random.uniform(0, 15)\n",
    "    # Random horizontal mirroring\n",
    "    flip = np.random.rand()\n",
    "    # Random translation\n",
    "    x_trans = np.random.randint(-20, 20)\n",
    "    y_trans = np.random.randint(-20, 20)\n",
    "    # Random zoom\n",
    "    scale = np.random.uniform(0.8, 1.2)\n",
    "    # Random cropping (with centralized region)\n",
    "    crop_size = np.random.randint(0.8 * min(frame_width, frame_height), min(frame_width, frame_height))\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    alpha = np.random.uniform(0.7, 1.3)\n",
    "    beta = np.random.randint(-20, 20)\n",
    "\n",
    "    return angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_frame(frame, angle, flip, x_trans, y_trans, scale, crop_size, alpha, beta, target_size):\n",
    "    \"\"\"\n",
    "    Apply various random transformations to an input image/frame.\n",
    "\n",
    "    Args:\n",
    "    - frame (numpy.ndarray): Input image/frame to be augmented.\n",
    "    - angle (float): Angle for random rotation.\n",
    "    - flip (float): Value for horizontal flipping (50% chance).\n",
    "    - x_trans (int): Random translation along the x-axis.\n",
    "    - y_trans (int): Random translation along the y-axis.\n",
    "    - scale (float): Random zoom factor.\n",
    "    - crop_size (int): Random size for cropping within the frame.\n",
    "    - alpha (float): Value for brightness and contrast adjustment.\n",
    "    - beta (int): Value for brightness and contrast adjustment.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Augmented image/frame after applying random transformations.\n",
    "    \"\"\"\n",
    "    # Random rotation by an angle\n",
    "    rows, cols, _ = frame.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows))\n",
    "    # Horizontal flipping\n",
    "    if flip > 0.5:  # 50% chance of flipping\n",
    "        frame = cv2.flip(frame, 1)\n",
    "    # Random translation\n",
    "    M = np.float32([[1, 0, x_trans], [0, 1, y_trans]])\n",
    "    frame = cv2.warpAffine(frame, M, (cols, rows))\n",
    "    # Random zoom\n",
    "    frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "    # Random cropping (with centralized region)\n",
    "    x = int((rows - crop_size) / 2)\n",
    "    y = int((cols - crop_size) / 2)\n",
    "    frame = frame[x:x + crop_size, y:y + crop_size]\n",
    "    # Changes in brightness, contrast, and saturation\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "    # Resize frame back to height 150, width 150\n",
    "    frame = cv2.resize(frame, target_size)\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_data(X, frames_per_video):\n",
    "    X_temp = np.empty((len(X), frames_per_video, *target_size, 3), dtype=np.uint8)\n",
    "    frame_height = X.shape[2]\n",
    "    frame_width = X.shape[3]\n",
    "\n",
    "    for i in range(len(X)):\n",
    "        angle, flip, x_trans, y_trans,\\\n",
    "        scale, crop_size, alpha, beta = augment_frame_params(frame_height, frame_width)\n",
    "        for j in range(frames_per_video):\n",
    "            sampled_frame = X[i][j]\n",
    "            aug_frame = augment_frame(sampled_frame,\n",
    "                                      angle,\n",
    "                                      flip,\n",
    "                                      x_trans,\n",
    "                                      y_trans,\n",
    "                                      scale,\n",
    "                                      crop_size,\n",
    "                                      alpha,\n",
    "                                      beta,\n",
    "                                      target_size)\n",
    "            X_temp[i][j] = aug_frame\n",
    "\n",
    "    return X_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ X_aug has been initialized with Shape (876, 10, 150, 150, 3)!\n",
      "✅ y_aug has been initialized with Shape (876, 20)!\n"
     ]
    }
   ],
   "source": [
    "# Define dataset multiplier\n",
    "number_of_augmentations = 3\n",
    "# Initialize a copy of preprocessed X and categoried y\n",
    "X_aug = X.copy()\n",
    "y_aug = y_cat.copy()\n",
    "\n",
    "# Multiply dataset by defined param\n",
    "for _ in range(number_of_augmentations):\n",
    "    X_temp = multiply_data(X, frames_per_video)\n",
    "    # Returns X_aug with shape (n * 219, 10, 150, 150, 3)\n",
    "    X_aug = np.concatenate((X_aug, X_temp), axis=0)\n",
    "    # Returns y_aug with shape (n * 219, 20)\n",
    "    y_aug = np.concatenate((y_aug, y_cat), axis=0)\n",
    "\n",
    "if X_aug.shape == ((number_of_augmentations + 1) * 219, 10, 150, 150, 3):\n",
    "    print(f'✅ X_aug has been initialized with Shape {X_aug.shape}!')\n",
    "else:\n",
    "    print('❌ X_aug has not been initialized properly!')\n",
    "\n",
    "if y_aug.shape == ((number_of_augmentations + 1) * 219, 20):\n",
    "    print(f'✅ y_aug has been initialized with Shape {y_aug.shape}!')\n",
    "else:\n",
    "    print('❌ y_aug has not been initialized properly!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_processed_videos(X_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SignFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
